# AMASS

Archive of Motion Capture as Surface Shapes (AMSS) fits a statistical body model to labeled marker-based optical motion capture data. It is probably the largest collection of human motion obtained from combining different optical marker-based motion capture datasets and representing in the same (SMPL-H based) parameterization, making it useful for animation, visualization, and generating training data for deep learning out-of-the-box.

This is based on a method called MoSh++, that converts mocap data into realistic 3D human meshes represented by a rigged body model.


![](https://raw.githubusercontent.com/nghorbani/amass/master/github_data/datasets_preview.png)


# Tutorial

![](https://camo.githubusercontent.com/aa7e55c214ddf16aa20717efb878a9d0d81c425724adf3ce802e0648edba27eb/68747470733a2f2f616d6173732e69732e7475652e6d70672e64652f75706c6f6164732f636b656469746f722f70696374757265732f312f7465617365722e676966)


- [Jupyter Notebooks](https://github.com/nghorbani/amass/tree/master/notebooks)

# Licenses

- [Public Repository for Non-Commerical Scientific Research Purposes](https://github.com/nghorbani/amass/)

- [Commericial License](#)


# Resources

[Paper](http://files.is.tue.mpg.de/black/papers/amass.pdf)


[Additional Paper](http://files.is.tue.mpg.de/black/papers/amass-sup.pdf)


[Poster](http://files.is.tue.mpg.de/black/papers/amass_iccv_poster.pdf)


[Project Video](https://youtu.be/cceRrlnTCEs)